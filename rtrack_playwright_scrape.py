import json
import sqlite3
import csv
import os
from datetime import datetime
from playwright.sync_api import sync_playwright

def main():
    # ç›®æ ‡ç½‘å€
    url = "https://rtrack.live/datasets"
    
    # è¿æ¥æ•°æ®åº“
    conn = sqlite3.connect("roblox_data.db")
    cur = conn.cursor()
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS concurrent_users (
            timestamp TEXT PRIMARY KEY,
            user_count INTEGER,
            fetched_at TEXT
        )
        """
    )

    # ç®€åŒ–çš„æ•°æ®æå–é€»è¾‘
    def extract_and_save(data):
        pts = []
        # å°è¯•å¯»æ‰¾å¸¸è§çš„å›¾è¡¨æ•°æ®ç»“æ„
        # é’ˆå¯¹ RTrack å¯èƒ½çš„ç»“æ„ 1: { "data": { "points": [...] } }
        # é’ˆå¯¹ RTrack å¯èƒ½çš„ç»“æ„ 2: [ [time, value], ... ]
        
        # é€’å½’æŸ¥æ‰¾åˆ—è¡¨
        def find_lists(obj):
            if isinstance(obj, list):
                # ç®€å•çš„å¯å‘å¼åˆ¤æ–­ï¼šå¦‚æœåˆ—è¡¨é‡Œçš„å…ƒç´ çœ‹èµ·æ¥åƒåæ ‡ç‚¹ [time, value]
                if len(obj) > 10 and isinstance(obj[0], (list, dict)): 
                    return [obj]
                return []
            elif isinstance(obj, dict):
                results = []
                for k, v in obj.items():
                    results.extend(find_lists(v))
                return results
            return []

        potential_lists = find_lists(data)
        
        count = 0
        now = datetime.utcnow().isoformat()

        for lst in potential_lists:
            for item in lst:
                ts = None
                val = None
                
                # å°è¯•è§£æ [timestamp, value] æ ¼å¼
                if isinstance(item, list) and len(item) >= 2:
                    ts = item[0]
                    val = item[1]
                # å°è¯•è§£æå­—å…¸æ ¼å¼ { "x": ..., "y": ... } æˆ– { "time": ..., "value": ... }
                elif isinstance(item, dict):
                    ts = item.get("x") or item.get("time") or item.get("AsOfHour") or item.get("timestamp")
                    val = item.get("y") or item.get("value") or item.get("PlatformConcurrent") or item.get("user_count")

                # åªæœ‰å½“æ—¶é—´å’Œæ•°å€¼éƒ½å­˜åœ¨ï¼Œä¸”æ•°å€¼çœ‹èµ·æ¥åƒæ˜¯ä¸€ä¸ªå¤§æ•´æ•°æ—¶æ‰ä¿å­˜
                if ts and val:
                    try:
                        val_int = int(float(val))
                        # è¿‡æ»¤æ‰æ˜¾ç„¶ä¸å¯¹çš„å°æ•°å­—ï¼ˆå¹¶å‘äººæ•°é€šå¸¸å¾ˆå¤§ï¼‰
                        if val_int > 1000: 
                            cur.execute(
                                "INSERT OR IGNORE INTO concurrent_users(timestamp, user_count, fetched_at) VALUES (?, ?, ?)",
                                (str(ts), val_int, now),
                            )
                            count += 1
                    except:
                        pass
        return count

    def on_response(response):
        try:
            # åªè¿‡æ»¤æ‰æ˜¾ç„¶æ˜¯å›¾ç‰‡ã€CSSã€JS çš„èµ„æº
            resource_type = response.request.resource_type
            if resource_type in ["image", "stylesheet", "font"]:
                return

            # æ‰“å°æ‰€æœ‰ JSON ç±»å‹çš„å“åº”ï¼Œç”¨äºè°ƒè¯•
            if "json" in response.headers.get("content-type", "").lower():
                print(f"ğŸ” å‘ç° JSON: {response.url} [Status: {response.status}]")
                
                try:
                    data = response.json()
                    saved_count = extract_and_save(data)
                    if saved_count > 0:
                        print(f"âœ… æˆåŠŸæå–å¹¶ä¿å­˜äº† {saved_count} æ¡æ•°æ®ï¼")
                except:
                    pass
        except Exception as e:
            print(f"Error processing response: {e}")

    with sync_playwright() as p:
        # æ·»åŠ  User-Agent ä¼ªè£…ï¼Œé˜²æ­¢è¢«è¯†åˆ«ä¸ºæœºå™¨äºº
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = context.new_page()
        
        print("ğŸš€ å¼€å§‹è®¿é—®é¡µé¢...")
        page.on("response", on_response)
        
        try:
            page.goto(url, wait_until="networkidle", timeout=60000)
            print("ğŸ“„ é¡µé¢åŠ è½½å®Œæˆï¼Œç­‰å¾…æ•°æ®åŒ…...")
            page.wait_for_timeout(15000) # å¤šç­‰ä¸€ä¼šå„¿
        except Exception as e:
            print(f"âš ï¸ é¡µé¢åŠ è½½è¶…æ—¶æˆ–å‡ºé”™: {e}")

        # å¯¼å‡º CSV
        csv_path = "concurrent_users.csv"
        saved_rows = 0
        with open(csv_path, "w", newline="", encoding="utf-8") as f:
            w = csv.writer(f)
            w.writerow(["timestamp", "user_count", "fetched_at"])
            for row in cur.execute("SELECT timestamp, user_count, fetched_at FROM concurrent_users ORDER BY timestamp"):
                w.writerow(row)
                saved_rows += 1
        
        print(f"ğŸ“Š æœ€ç»ˆ CSV æ–‡ä»¶åŒ…å« {saved_rows} è¡Œæ•°æ®ã€‚")
        
        browser.close()
        conn.close()

if __name__ == "__main__":
    main()
